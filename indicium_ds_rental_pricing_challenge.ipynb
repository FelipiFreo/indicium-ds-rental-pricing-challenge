{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1DsGFyb4VLOc0bYu4QSS4Jy4nD1t7zwcL",
      "authorship_tag": "ABX9TyNlqMaCECv5pEsHcZBT4in6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FelipiFreo/indicium-ds-rental-pricing-challenge/blob/main/indicium_ds_rental_pricing_challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P_obdfzSgXaS"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.preprocessing import LabelEncoder, PolynomialFeatures\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.pipeline import make_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file from Google Drive\n",
        "!pip install gdown\n",
        "\n",
        "import gdown\n",
        "\n",
        "file_id = '1oVQ1xzFkkavnCu4usj3oEfrhOVQG-Dtt'\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "output = 'Desafio Ciência de Dados - Precificação 2024-4.csv'\n",
        "\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "df = pd.read_csv(output)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLwLKMc9DNIL",
        "outputId": "f6d63544-084f-4ed5-b6b5-034a9132aeea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1oVQ1xzFkkavnCu4usj3oEfrhOVQG-Dtt\n",
            "To: /content/Desafio Ciência de Dados - Precificação 2024-4.csv\n",
            "100%|██████████| 7.08M/7.08M [00:00<00:00, 72.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Exploratory Data Analysis (EDA)\n",
        "\n",
        "# Explore price distribution\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(df['price'], bins=100, kde=True)\n",
        "plt.title('Price Distribution')\n",
        "plt.xlim(0, 1000)\n",
        "plt.show()\n",
        "\n",
        "# Relationship between variables\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.scatterplot(x='disponibilidade_365', y='price', data=df, hue='bairro_group', palette='viridis')\n",
        "plt.title('Availability throughout the year vs. Price')\n",
        "plt.show()\n",
        "\n",
        "# Relationship between variables\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.scatterplot(x='minimo_noites', y='price', data=df, hue='bairro_group', palette='viridis')\n",
        "plt.title('Minimo noites vs. Price')\n",
        "plt.show()\n",
        "\n",
        "# Word cloud from the names of places\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(df['nome'].astype(str)))\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.title('Word Cloud - Place Names')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8gHvW_eOk41h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the correlation matrix\n",
        "corr = df.corr()\n",
        "\n",
        "# Create a heatmap to visualize the correlation matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True)\n",
        "plt.title('Correlation Matrix of All Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6n9vGLkLk8PZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Answers to Questions:\n",
        "\n",
        "# a. Location to Invest\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x='bairro_group', y='price', data=df, palette='viridis', hue='bairro_group', legend=False)\n",
        "plt.title('Average Price per Neighborhood')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()\n",
        "\n",
        "# b. Impact of Minimum Nights and Availability\n",
        "correlation_nights_availability_price = df[['minimo_noites', 'disponibilidade_365', 'price']].corr()\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlation_nights_availability_price, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation between Minimum Nights, Availability, and Price')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-mhHW3vgk94y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Price Prediction:\n",
        "\n",
        "# Encode categorical variable 'bairro_group'\n",
        "le_bairro = LabelEncoder()\n",
        "df['bairro_group_encoded'] = le_bairro.fit_transform(df['bairro_group'])\n",
        "\n",
        "# Train the model (Polynomial Regression)\n",
        "poly_degree = 2  # Degree of the polynomial\n",
        "\n",
        "polyreg = make_pipeline(PolynomialFeatures(poly_degree), LinearRegression())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df[['bairro_group_encoded', 'minimo_noites', 'disponibilidade_365']],\n",
        "    df['price'],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "polyreg.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "uLY9ix0OlqAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model as a pickle string.\n",
        "\n",
        "model = polyreg.fit(X_train_scaled, y_train)\n",
        "\n",
        "saved_model = 'my_model.pkl'\n",
        "with open(saved_model, 'wb') as file:\n",
        "  pickle.dump(model, file)"
      ],
      "metadata": {
        "id": "Kb11YgW3ermo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Price Suggestion:\n",
        "\n",
        "# Data for the apartment with the provided characteristics\n",
        "apartment_data = {\n",
        "    'bairro_group': 'Manhattan',\n",
        "    'minimo_noites': 1,\n",
        "    'disponibilidade_365': 355\n",
        "}\n",
        "\n",
        "# Create a DataFrame for the new apartment\n",
        "apartment_df = pd.DataFrame(apartment_data, index=[0])\n",
        "\n",
        "# Encode categorical variable for the new apartment\n",
        "apartment_df['bairro_group_encoded'] = le_bairro.transform(apartment_df['bairro_group'])\n",
        "\n",
        "# Scale the data\n",
        "apartment_scaled = scaler.transform(apartment_df[['bairro_group_encoded', 'minimo_noites', 'disponibilidade_365']])\n",
        "\n",
        "# Predict the price for the new apartment using Polynomial Regression\n",
        "predicted_price = polyreg.predict(apartment_scaled)\n",
        "\n",
        "# Visualization of average prices per neighborhood after the price suggestion\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x='bairro_group', y='price', data=df, palette='viridis', hue='bairro_group', legend=False)\n",
        "plt.title('Average Price per Neighborhood after Suggestion')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.ylim(0, 300)\n",
        "\n",
        "# Annotation for the price suggestion\n",
        "plt.annotate(\n",
        "    f'Price Suggestion: {predicted_price[0]:.2f}',\n",
        "    xy=(0.5, 0), xycoords='axes fraction', ha='center',\n",
        "    bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"white\"),\n",
        "    fontsize=10, color='black'\n",
        ")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VJfRBuMWls86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "RY1X_sxtlwAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerar um arquivo de requisitos\n",
        "!pip freeze > requirements.txt\n"
      ],
      "metadata": {
        "id": "l1F9EC9EX6rg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}